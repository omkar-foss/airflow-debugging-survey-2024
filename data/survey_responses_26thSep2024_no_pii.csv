Timestamp,1.1. What issues have you encountered with Airflow logs?,"1.1.1. Other issues, examples or clarifications:",1.2. What challenges have you been facing with Airflow's stack traces?,1.2.1. Other challenges:,1.3. How would you rate the ease of understanding stack traces in Airflow?,1.4. What improvements to Airflow’s traceback information would make debugging easier?,1.4.1. Potential improvements:,2.1. What issues have you encountered with Airflow error messages?,2.1.1. Other issues:,2.2. How would you rate the clarity & actionability of Airflow error messages?,2.3. Which of the following suggestions would improve Airflow's error handling? [1st],2.3. Which of the following suggestions would improve Airflow's error handling? [2nd],2.3. Which of the following suggestions would improve Airflow's error handling? [3rd],2.3. Which of the following suggestions would improve Airflow's error handling? [4th],2.3. Which of the following suggestions would improve Airflow's error handling? [5th],3.1. Which tools do you use to develop Airflow DAGs?,3.2. How satisfied are you with Airflow’s integration with modern debugging tools and the related documentation?,"3.3. How often do you use external tools (i.e. besides Airflow's API, UI, and CLI) to supplement Airflow's debugging capabilities?",3.4. What sort of external tools do you use in conjunction with Airflow for debugging?,3.5. What integrations or tooling improvements would you like to see in Airflow to enhance your debugging experience?,3.6. Which of the following code assistance and inspection tools do you use while developing Airflow DAGs?,4.1. What is the most time-consuming activity related to developing new DAGs? [Business logic],4.1. What is the most time-consuming activity related to developing new DAGs? [DAG authoring],4.1. What is the most time-consuming activity related to developing new DAGs? [Iteration],4.1. What is the most time-consuming activity related to developing new DAGs? [Integration],4.1. What is the most time-consuming activity related to developing new DAGs? [Maintenance],4.2 What can be improved about the workflow activities mentioned above?,4.3. How often do you leave the Airflow UI or CLI (and rely on external tools) to achieve each of the above? [Business logic],4.3. How often do you leave the Airflow UI or CLI (and rely on external tools) to achieve each of the above? [DAG authoring],4.3. How often do you leave the Airflow UI or CLI (and rely on external tools) to achieve each of the above? [Iteration],4.3. How often do you leave the Airflow UI or CLI (and rely on external tools) to achieve each of the above? [Integration],4.3. How often do you leave the Airflow UI or CLI (and rely on external tools) to achieve each of the above? [Maintenance],4.4. Which of the following additions to the Airflow UI could be useful to your debugging efforts?,4.4.1. Other suggestions:,4.5. What could make DAG.test() more useful?,4.5.1. Other suggestions:,4.6. What kind of remote Airflow environment(s) do you use?,"4.7. How would you rate the ease of debugging DAGs in a remote Airflow environment (Kubernetes, Docker, etc.)?",4.7.1. What can make debugging a remote Airflow deployment easier or more efficient?,5.1. How would you describe your proficiency level with Airflow?,5.2. What are your responsibilities in the context of using Airflow?,5.3. How would you describe your role in the context where you use Airflow most often?,6.1. Free-form feedback,"6.2. Feedback about the survey itself (length, thoroughness, relevance, etc.)"
9/18/2024 8:47:54,"Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,Stack traces do not provide enough context about the DAG execution state,,4,,"Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure","Example of a misleading error message: if the webserver is set up to use ldap, and the python-ldap dependency is missing, inputting the right user will say that the credentials are wrong instead of issuing an ""internal server error; consult the logs"" ",3,D,G,F,H,A,"Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,5,"Debuggers (e.g., pdb, debugpy, PyCharm)","Attaching to a ""remote"" Airflow instance should be easier and better documented.","Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",3rd,4th,Most,2nd,Least,"Maintenance - in my case this involves amendments to the DAG due to unforeseen/unaccounted issues encountered in productions. For example: trying to save a file to a folder containing the year or month, without checking that the folder exists - will fail for the first dagruns of the month/year. A lint warning when saving files without first verifying the destination's existence would be ideal in this case.",Always,Always,Often,Often,Often,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,"Bare metal or VM-based install, Docker",1,"Better documentation of how to attach a debugger to a particular DAG{run}, with step by step instructions for at least vscode and pycharm. Perhaps add a UI checkbox that says ""delay execution until a debugger is attached"".",Advanced (made and debugged several DAGs over the last few years),"DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator)","Senior team member, Technical supervisor (e.g software architect)","Being able to save, share, and restore a debugging session would be amazing.","We should be more careful with ""linear scale"" questions, to always ensure that a consistent  side means the ""current state is good"" and the other meaning the opposite."
9/2/2024 19:10:20,"Logs are fragmented across different systems/components, Logs are not verbose enough, Logs are too verbose, Logs are non-existent or missing in some cases","Looping within the scheduler makes logs really hard to read.  Logs frequently don't say why a task isn't running e.g. various parallelism limits, time of day restrictions,  celery workers at max concurrence,  etc.  ",,,4,,"More detailed context about the state of the DAG and task at the time of failure, Integration with visualization tools to trace execution flow","Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure",,2,B,A,E,,,"Text editor (e.g., Vim, Notepad++), Source code editor (e.g., VSCode, Sublime Text)",3,1,"Log management systems (e.g., ELK Stack, Splunk)",Remote debugging of tasks through vscode. ,"Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",2nd,4th,Most,3rd,,"Making it easier to upload a new dag, clear a specific task, and rerun it, and see logs in a single ide command. Parsing the dagbag right away when it changes. ",Often,Always,Rarely,Rarely,Always,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,"Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,"Self-Managed Airflow on Kubernetes (using official Helm Chart), Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.), Bare metal or VM-based install",1,"Apis to write extensions for ides that allow uploading of dags and synchronously forxing the reparse of a dag, apis to fetch mark a task as a debug breakpoint and fetch a url ides can connect to to stream logs and apis to fetch a puthon remote debugger endpoint for vscode","Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.)",Astronomer employee,,,
9/2/2024 20:59:44,"Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,,,,,Integration with visualization tools to trace execution flow,"Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues",,,,,,,,"Source code editor (e.g., VSCode, Sublime Text), Jupyter Notebooks",2,1,"Monitoring tools (e.g., Prometheus, Grafana)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",,,,,,,,,,,,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,Self-Managed Airflow on Kubernetes (using official Helm Chart),3,,Advanced (made and debugged several DAGs over the last few years),"DAG development (e.g. Data Engineer, Software Developer)",Junior team member,,
9/2/2024 21:00:29,"Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",Maybe colour coding for Errors and Warnings will be helpful,Stack traces are incomplete or missing critical information,,3,,"Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces",Error messages are inconsistent across different components,,3,A,E,B,D,I,"Text editor (e.g., Vim, Notepad++), Source code editor (e.g., VSCode, Sublime Text)",3,4,"Monitoring tools (e.g., Prometheus, Grafana)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",2nd,3rd,3rd,Most,2nd,,Sometimes,Rarely,Rarely,Never,Never,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,"Mock file system queries/reads/writes, Mock network requests/responses, Ability to jump into a specific task/operator with a user-provided state",,Airflow installed on AWS EC2,2,,"Advanced (made and debugged several DAGs over the last few years), Administrator (supported Airflow installations at a platform level)","Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Technical supervisor (e.g software architect),,Thank you for all the work you guys doing ..
9/2/2024 21:36:18,"Logs are fragmented across different systems/components, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,Stack traces do not provide enough context about the DAG execution state,,3,,"Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure, Error messages are inconsistent across different components",,2,D,C,A,G,F,"Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,4,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana), Debuggers (e.g., pdb, debugpy, PyCharm)",,,Least,4th,Most,2nd,3rd,,Never,Rarely,Sometimes,Always,Often,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,Self-Managed Airflow on Kubernetes (using official Helm Chart),2,,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.)","DAG development (e.g. Data Engineer, Software Developer)",Technical supervisor (e.g software architect),,
9/2/2024 21:58:00,"Logs are fragmented across different systems/components, Logs are non-existent or missing in some cases",,Stack traces are incomplete or missing critical information,,3,,"Better correlation between different logs and stack traces, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages are inconsistent across different components",,3,D,H,A,B,F,"Source code editor (e.g., VSCode, Sublime Text)",2,5,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",2nd,4th,Most,3rd,Least,,Always,Always,Sometimes,Sometimes,Never,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events",,Self-Managed Airflow on Kubernetes (using official Helm Chart),1,,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Technical supervisor (e.g software architect),,
9/2/2024 22:20:35,"Logs are too verbose, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,Stack traces do not provide enough context about the DAG execution state,,3,,"Inclusion of specific suggestions or hints for resolving the issue, Integration with visualization tools to trace execution flow",Error messages do not provide clear guidance on resolving issues,,3,F,G,H,B,A,"Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,1,"Debuggers (e.g., pdb, debugpy, PyCharm)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",3rd,4th,2nd,Most,,,Always,Always,,Sometimes,Rarely,"Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,Mock dataset events,,Self-Managed Airflow on Kubernetes (using official Helm Chart),3,,Beginner (made a handful of DAGs recently),"DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)","Senior team member, Technical supervisor (e.g software architect)",,
9/2/2024 22:55:59,,"Logs disappear when there are infra problems, eg out of memory",,,2,,,,,2,G,,,,,"Source code editor (e.g., VSCode, Sublime Text)",1,5,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana), Profiling tools (e.g. cProfile, Austin), Debuggers (e.g., pdb, debugpy, PyCharm)",Easier to run locally; easier to integrate with VS code debugger,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",2nd,Least,,4th,3rd,Make it easier to run locally; make it easier to debug with IDE such as VS code,Always,Rarely,Often,Sometimes,Sometimes,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.)",Easier to run locally and integrate with debugger in IDE such as VS code,,,Self-Managed Airflow on Kubernetes (using official Helm Chart),2,"Export statistics to CSV. I often use the ""Browse"" tab (""Dag runs"" or ""Task instances"") to check for failures, durations, etc. and further analysis, such as % of failures or duration statistics involve high effort such as parsing the html into excel, or creating a script to fetch this info from the API.","Beginner (made a handful of DAGs recently), Advanced (made and debugged several DAGs over the last few years)","DAG development (e.g. Data Engineer, Software Developer)",Senior team member,Easier to run locally and integrate with debugger in IDE such as VS code,
9/3/2024 1:22:49,"Logs are fragmented across different systems/components, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,Stack traces do not provide enough context about the DAG execution state,,3,,"Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues",,2,A,B,D,E,F,"Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,2,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",2nd,Least,3rd,Most,4th,Documentation around integration can be improved providing more explanation different parameters with some examples.,Often,Never,Sometimes,Often,Rarely,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,"Mock network requests/responses, Mock dataset events, Ability to jump into a specific task/operator with a user-provided state",,Self-Managed Airflow on Kubernetes (using official Helm Chart),2,,"Advanced (made and debugged several DAGs over the last few years), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow monitoring & availability (e.g. SRE, DevOps)",Technical supervisor (e.g software architect),,
9/3/2024 1:57:02,"Logs are fragmented across different systems/components, Logs are non-existent or missing in some cases",,Stack traces are too complex and hard to follow,,3,,"Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure, Error messages are inconsistent across different components",,1,F,D,E,E,D,"Source code editor (e.g., VSCode, Sublime Text)",1,3,"Monitoring tools (e.g., Prometheus, Grafana), Tracing tools (e.g., Jaeger, Zipkin, OpenTelemetry), Debuggers (e.g., pdb, debugpy, PyCharm)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",2nd,3rd,3rd,3rd,3rd,,Sometimes,Sometimes,Sometimes,Sometimes,Sometimes,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",4,,Advanced (made and debugged several DAGs over the last few years),"DAG development (e.g. Data Engineer, Software Developer)",Senior team member,,
9/3/2024 5:20:16,"Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,"Stack traces are too complex and hard to follow, Stack traces do not provide enough context about the DAG execution state",,3,color coding according to criticality,"Simplified and more readable stack traces, Integration with visualization tools to trace execution flow","Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure",,3,C,I,H,J,F,"Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,3,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana), Datadog - Airflow metrics and logs monitoring",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",Most,4th,3rd,2nd,Least,,Always,Never,Sometimes,Sometimes,Rarely,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,Store/load the state of a DAG,,"Self-Managed Airflow on Kubernetes (using official Helm Chart), Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.), Bare metal or VM-based install",2,,"Beginner (made a handful of DAGs recently), Advanced (made and debugged several DAGs over the last few years), Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)","Senior team member, Technical supervisor (e.g software architect)",,
9/3/2024 6:21:40,"Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,,,3,,"Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue",Error messages are vague or non-specific,,3,G,E,I,D,A,Jupyter Notebooks,3,4,"Debuggers (e.g., pdb, debugpy, PyCharm)",,"Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",,,,Most,,,Often,,,Sometimes,,,,,,,,,,,Junior team member,,
9/3/2024 7:21:13,"Logs are fragmented across different systems/components, Logs are too verbose, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,Stack traces do not provide enough context about the DAG execution state,,3,,"Simplified and more readable stack traces, Better correlation between different logs and stack traces",Error messages are inconsistent across different components,,3,D,H,F,G,J,"Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,4,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",Least,4th,Most,2nd,3rd,,Rarely,Rarely,Often,Often,Sometimes,"Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Ability to jump into a specific task/operator with a user-provided state",,Self-Managed Airflow on Kubernetes (using official Helm Chart),2,,"Advanced (made and debugged several DAGs over the last few years), Administrator (supported Airflow installations at a platform level)","Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Technical supervisor (e.g software architect),,
9/3/2024 7:42:57,,"Windows

Plz bring it to windows...............................",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9/3/2024 14:19:09,Logs are non-existent or missing in some cases,,Stack traces are too complex and hard to follow,,3,,"More detailed context about the state of the DAG and task at the time of failure, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages lack context or details about the failure, Error messages are inconsistent across different components",,2,C,J,A,D,E,"Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,4,"Debuggers (e.g., pdb, debugpy, PyCharm)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",Least,4th,2nd,3rd,Most,,Often,Never,Never,Never,Never,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,,2,,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.)","DAG development (e.g. Data Engineer, Software Developer), Airflow monitoring & availability (e.g. SRE, DevOps)","Junior team member, Senior team member",,
9/3/2024 16:04:59,Logs are non-existent or missing in some cases,,Stack traces do not provide enough context about the DAG execution state,,4,,"More detailed context about the state of the DAG and task at the time of failure, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow",Error messages do not provide clear guidance on resolving issues,,2,D,F,G,B,H,"Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,5,"Debuggers (e.g., pdb, debugpy, PyCharm)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",4th,Least,Most,2nd,3rd,,Always,Always,Always,Always,Often,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.","Have the task instance view in the UI supply the airflow task test config params as a copyable resource like the task id. Consider that these are probably being run in an IDE and we generally need the params, not the command 
`airflow task test` # < standardized in IDE# {params} #< needed each time
","Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.), Bare metal or VM-based install",,,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)","Senior team member, Technical supervisor (e.g software architect)",,
9/3/2024 18:43:09,"Logs are too verbose, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,"Stack traces are too complex and hard to follow, Stack traces do not provide enough context about the DAG execution state",,3,Improve the readability and searching of the logs using colors and other UI features.,"Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure",,3,G,A,F,D,B,"Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",1,5,"Debuggers (e.g., pdb, debugpy, PyCharm), astro CLI",Allow full debugging of an Airflow DAG from start to finish,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint)",Most,3rd,2nd,4th,Least,Perhaps support the ability to modify a DAG from the Airflow UI specifically for debugging/testing purposes. The changes could be temporary and discarded once finished.,Always,Often,Sometimes,Always,Always,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Ability to jump into a specific task/operator with a user-provided state",,"Self-Managed Airflow on Kubernetes (using official Helm Chart), Bare metal or VM-based install",2,,Administrator (supported Airflow installations at a platform level),"DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Technical supervisor (e.g software architect),,
9/3/2024 19:01:39,,,,,5,,"Simplified and more readable stack traces, Inclusion of specific suggestions or hints for resolving the issue, Integration with visualization tools to trace execution flow",,,3,,,,,,"Source code editor (e.g., VSCode, Sublime Text)",2,2,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana)",log export to Kafka,"Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",Most,3rd,Most,2nd,4th,log export to kafka,Sometimes,Rarely,Rarely,Sometimes,Sometimes,"Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,,,Bare metal or VM-based install,3,,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.)","DAG development (e.g. Data Engineer, Software Developer)",Senior team member,,
9/3/2024 19:11:17,"Logs are non-existent or missing in some cases, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",Logs for removed tasks are not visible through the UI. Cloud watch logs for AWS operators (ex. AWSBatchOperator) are not visible through the Airflow UI,,,,,"Better correlation between different logs and stack traces, Integration with visualization tools to trace execution flow",Error messages lack context or details about the failure,,2,E,F,G,D,J,"Text editor (e.g., Vim, Notepad++), Source code editor (e.g., VSCode, Sublime Text)",2,4,"Monitoring tools (e.g., Prometheus, Grafana), Tracing tools (e.g., Jaeger, Zipkin, OpenTelemetry), Debuggers (e.g., pdb, debugpy, PyCharm)",Ability to easy debug containerized (docker-compose) local Airflow stack via VS Code/Codium,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",4th,3rd,2nd,Most,Least,Add interface to automate connection to API endpoints & load data the same way Airbyte or River.io work,Always,Always,Rarely,Often,Never,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.)",Provide a way to access logs for tasks that no longer exist in the DAG interface. Provide a UI interface for backfilling (CLI is not available to users). Better support for debugging Airflow running in Docker via VS Code/Codium,"Mock dataset events, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,AWS ECS,1,Better VS Code/Codium support,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Technical supervisor (e.g software architect),,
9/3/2024 19:14:10,"Logs are fragmented across different systems/components, Logs are non-existent or missing in some cases",,,,4,,,,,,,,,,,"Source code editor (e.g., VSCode, Sublime Text)",,,,"Remote Workers SetUp. Instead of TCP connections, need to go for http for connection robustness b/w remote workers and  cloud ","Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",,,Most,2nd,,,,,,,,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,,,Self-Managed Airflow on Kubernetes (using official Helm Chart),1,,Administrator (supported Airflow installations at a platform level),"DAG development (e.g. Data Engineer, Software Developer)",Senior team member,,
9/3/2024 19:14:36,"Logs are fragmented across different systems/components, Logs are too verbose",,Stack traces are too complex and hard to follow,,2,,"Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues",,1,D,C,J,,,"Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",1,1,,,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",Least,4th,Most,3rd,2nd,,Always,Always,Often,Rarely,Sometimes,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,,Integrate with variables directory somehow,Self-Managed Airflow on Kubernetes (using official Helm Chart),2,,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Technical supervisor (e.g software architect),,Too long
9/3/2024 19:16:03,"Logs are non-existent or missing in some cases, Logs are difficult to search and filter",,Stack traces do not provide enough context about the DAG execution state,,3,,"More detailed context about the state of the DAG and task at the time of failure, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes","Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure",,3,D,E,G,F,C,"Source code editor (e.g., VSCode, Sublime Text)",3,4,"Monitoring tools (e.g., Prometheus, Grafana)","cluster activity tab has a lot of potential, more overview capabilities of all dags","Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",Most,3rd,2nd,Least,4th,,Often,Sometimes,Often,Often,Sometimes,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,"Mock network requests/responses, Store/load the state of a DAG",,Self-Managed Airflow on Kubernetes (using official Helm Chart),3,,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Senior team member,,
9/3/2024 19:20:37,"Logs are not verbose enough, Logs are non-existent or missing in some cases, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,Stack traces are incomplete or missing critical information,,3,,"More detailed context about the state of the DAG and task at the time of failure, Enhanced visibility of nested errors and their causes","Error messages are vague or non-specific, Error messages lack context or details about the failure",,3,C,C,C,C,C,"Source code editor (e.g., VSCode, Sublime Text)",3,1,,,,3rd,Least,Most,4th,2nd,,Sometimes,Sometimes,Sometimes,Sometimes,Sometimes,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,"Mock file system queries/reads/writes, Mock dataset events, Store/load the state of a DAG",,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",1,,Advanced (made and debugged several DAGs over the last few years),"DAG development (e.g. Data Engineer, Software Developer)",Senior team member,,
9/3/2024 19:32:31,Logs are difficult to search and filter,,Stack traces do not provide enough context about the DAG execution state,,3,,"More detailed context about the state of the DAG and task at the time of failure, Enhanced visibility of nested errors and their causes",Error messages do not provide clear guidance on resolving issues,,3,B,D,G,H,J,"Source code editor (e.g., VSCode, Sublime Text)",1,1,"Monitoring tools (e.g., Prometheus, Grafana)",,"Formatters (e.g. Black, Ruff-format, autopep8)",Least,3rd,4th,2nd,Most,,Always,Always,Never,Always,Always,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,"Mock file system queries/reads/writes, Mock network requests/responses",,Bare metal or VM-based install,2,,"Advanced (made and debugged several DAGs over the last few years), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",middle devops/sre,,ok
9/3/2024 19:53:39,"Logs are fragmented across different systems/components, Logs are non-existent or missing in some cases",,"Stack traces are too complex and hard to follow, Stack traces are incomplete or missing critical information, Stack traces do not provide enough context about the DAG execution state",,3,,"More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure, Error messages are inconsistent across different components",,3,J,A,C,B,D,"Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",3,4,"Monitoring tools (e.g., Prometheus, Grafana)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",3rd,2nd,4th,Most,Least,,Often,Often,Often,Often,Often,"An integrated terminal in the UI, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Ability to jump into a specific task/operator with a user-provided state",,"Self-Managed Airflow on Kubernetes (using official Helm Chart), Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",3,,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level)","Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Senior team member,,
9/3/2024 19:55:30,"Logs are not verbose enough, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,Stack traces do not provide enough context about the DAG execution state,,3,,"More detailed context about the state of the DAG and task at the time of failure, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow",Error messages lack context or details about the failure,,3,D,E,J,G,A,"Source code editor (e.g., VSCode, Sublime Text)",3,3,"Debuggers (e.g., pdb, debugpy, PyCharm)","Clarification and more detailed documentation on how setup airflow variables/connections for debugging (dag.test()) sessions. Currently there are a lot of options, airflow cli, yaml, json, .env etc, but none of them documented enough. For example how to init/mock airflow vars/conn for debug session to use them before DAG will be executed (for example to use variables in DAG decorator parameters).","Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",3rd,4th,2nd,Most,,"For me working with vars/conn in debug sessions is most painfull, because airflow cli doesn't work as expected, with astro cli I used airflow_settings.yml, but airflow cli doesn't understand that format, in docs there are a couple of other formats like yml/json, airflow.cfg or smth like that to define variables and connections, but they are not consistent to each other and not documented well enough",Sometimes,Sometimes,Sometimes,Sometimes,Sometimes,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests.",,,,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",2,integrated console to at least inspect  env variables and file system,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.)","DAG development (e.g. Data Engineer, Software Developer), Airflow monitoring & availability (e.g. SRE, DevOps)","Senior team member, Technical supervisor (e.g software architect)",,
9/3/2024 19:56:38,"Logs are non-existent or missing in some cases, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,,,3,,"Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages are inconsistent across different components",,2,D,F,G,C,J,"Source code editor (e.g., VSCode, Sublime Text)",1,4,"Log management systems (e.g., ELK Stack, Splunk), Debuggers (e.g., pdb, debugpy, PyCharm)",Extension for vs code for parsing dags ,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",4th,3rd,Most,2nd,Least,,Always,Often,Rarely,Sometimes,Sometimes,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,"Mock file system queries/reads/writes, Mock network requests/responses, Store/load the state of a DAG",,Self-Managed Airflow on Kubernetes (using official Helm Chart),3,,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)","Senior team member, Technical supervisor (e.g software architect)",,
9/3/2024 20:13:34,"Logs are fragmented across different systems/components, Logs are non-existent or missing in some cases, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,"Stack traces are too complex and hard to follow, Stack traces are incomplete or missing critical information, Stack traces do not provide enough context about the DAG execution state",,2,,"Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure, Error messages are inconsistent across different components",,1,D,G,J,I,A,"Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse), Jupyter Notebooks",2,3,"Monitoring tools (e.g., Prometheus, Grafana), Debuggers (e.g., pdb, debugpy, PyCharm)",,"Formatters (e.g. Black, Ruff-format, autopep8)",Most,,4th,2nd,3rd,,Always,Always,Always,Always,Always,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,"Self-Managed Airflow on Kubernetes (using official Helm Chart), Bare metal or VM-based install",2,,Advanced (made and debugged several DAGs over the last few years),"DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Senior team member,,
9/3/2024 22:22:27,"Logs are fragmented across different systems/components, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,"Stack traces are incomplete or missing critical information, Stack traces do not provide enough context about the DAG execution state",,3,,"More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure",,2,G,B,A,D,E,"Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",1,1,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",3rd,4th,2nd,Most,Least,,Always,Always,Always,Always,Always,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,,,Bare metal or VM-based install,1,,"Advanced (made and debugged several DAGs over the last few years), Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator)",Senior team member,,
9/3/2024 23:47:44,"Logs are non-existent or missing in some cases, Logs are difficult to search and filter",The filter functionality in dag runs is completely broken. ,,DAGs that can be successfully run as Python files sometimes are not parsed by the dag processor,3,,"More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Enhanced visibility of nested errors and their causes","Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure",,3,B,E,F,A,,"Source code editor (e.g., VSCode, Sublime Text)",2,5,"Monitoring tools (e.g., Prometheus, Grafana)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor), Pre-commit hooks to run DAGs as Python scripts to prevent import errors",3rd,Least,Most,2nd,4th,"The docker-compose is incredibly slow, I spend most of my development cycle there and if there was a better alternative it would save me lots of time.

Parsing of DAGs continues to be the most painful part of airflow dev.",Often,Often,Often,Often,Sometimes,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,"Self-Managed Airflow on Kubernetes (using official Helm Chart), ",2,"Better monitoring / logging of resource consumption. Typically when something goes down, the error messages are not helpful at all.","Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.)","DAG development (e.g. Data Engineer, Software Developer)",Senior team member,,
9/4/2024 5:00:15,"Logs are fragmented across different systems/components, Logs are difficult to search and filter",,,,4,,"More detailed context about the state of the DAG and task at the time of failure, Inclusion of specific suggestions or hints for resolving the issue, Integration with visualization tools to trace execution flow",,,3,,,,,,"Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,2,"Debuggers (e.g., pdb, debugpy, PyCharm)","Out of the box, easy plug-and-play integrations with log management's like logz.io, monitoring and tracing tools","Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",4th,Least,2nd,Most,Least,,,,,,,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,,,Self-Managed Airflow on Kubernetes (using official Helm Chart),1,Built in debugger with breakpoints,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.)","DAG development (e.g. Data Engineer, Software Developer)","Senior team member, Technical supervisor (e.g software architect)",,
9/4/2024 9:24:26,,,,,5,,"More detailed context about the state of the DAG and task at the time of failure, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow",,,4,F,J,I,G,D,"Source code editor (e.g., VSCode, Sublime Text)",4,4,"Monitoring tools (e.g., Prometheus, Grafana)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint)",2nd,3rd,Most,4th,Least,,Always,Always,Sometimes,Never,Never,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,Bare metal or VM-based install,4,,"Advanced (made and debugged several DAGs over the last few years), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)","Senior team member, Lone developer (e.g. independent consultant)",,
9/4/2024 14:03:30,Logs are difficult to search and filter,,Stack traces are incomplete or missing critical information,,2, ,"Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow",,,4,,,,,,"Text editor (e.g., Vim, Notepad++), Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,2,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana)",More support for debugging,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",Least,4th,Most,2nd,3rd,,Sometimes,Sometimes,Often,Often,Sometimes,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests.",,"Mock file system queries/reads/writes, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,Self-Managed Airflow on Kubernetes (using official Helm Chart),2,,Advanced (made and debugged several DAGs over the last few years),"DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Junior team member,Thanks for making airflow such a great product!,
9/4/2024 14:08:30,"Logs are non-existent or missing in some cases, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,,,4,,"Inclusion of specific suggestions or hints for resolving the issue, Integration with visualization tools to trace execution flow",,,3,I,F,,,,"Source code editor (e.g., VSCode, Sublime Text)",2,4,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana), Debuggers (e.g., pdb, debugpy, PyCharm)",,,4th,3rd,Most,2nd,Least,,,,,,,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,"Mock network requests/responses, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,"Self-Managed Airflow on Kubernetes (using official Helm Chart), Bare metal or VM-based install",2,,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Technical supervisor (e.g software architect),"There should be some mechanism to update the dag on the go and test. Also, open telemetry integration and  stats that we are sending should also be improved.",
9/4/2024 16:54:53,"Logs are fragmented across different systems/components, Logs are not verbose enough, Logs are difficult to search and filter",,"Stack traces are incomplete or missing critical information, Stack traces do not provide enough context about the DAG execution state",,3,,"More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure",,2,B,E,F,G,D,"Text editor (e.g., Vim, Notepad++), Source code editor (e.g., VSCode, Sublime Text)",1,2,"Monitoring tools (e.g., Prometheus, Grafana)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",4th,3rd,Most,Least,2nd,,Always,Rarely,Often,Often,Sometimes,"An integrated terminal in the UI, A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file.",,,,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",2,,Advanced (made and debugged several DAGs over the last few years),"DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)","Junior team member, Lone developer (e.g. independent consultant)",,
9/4/2024 18:30:25,Logs are non-existent or missing in some cases,,Stack traces do not provide enough context about the DAG execution state,,3,,"Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow",Error messages do not provide clear guidance on resolving issues,,3,D,E,F,J,C,"Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse), Jupyter Notebooks, Cloud-based development environments (e.g., AWS Cloud9, GitHub Codespaces)",3,1,,,,4th,2nd,3rd,Most,Least,,Rarely,Often,Often,Never,Never,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,,,"Self-Managed Airflow on Kubernetes (using official Helm Chart), Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",3,,Advanced (made and debugged several DAGs over the last few years),"DAG development (e.g. Data Engineer, Software Developer)","Junior team member, Lone developer (e.g. independent consultant)",,
9/4/2024 18:56:54,"Logs are fragmented across different systems/components, Logs are too verbose, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,"Stack traces are too complex and hard to follow, Stack traces do not provide enough context about the DAG execution state",,4,Folks often get confused when there's multiple exceptions. That's unfortunately just python behavior. It can be misleading when the real error requires scrolling back up from the bottom. ,"Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure",,3,A,B,G,J,E,"Text editor (e.g., Vim, Notepad++), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse), Cloud-based development environments (e.g., AWS Cloud9, GitHub Codespaces)",2,3,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana), Debuggers (e.g., pdb, debugpy, PyCharm)","It can be difficult to use a debugger due to the highly coupled nature of Airflow. Can't run a debugger, unless you have a fully initialized database and all the right python deps installed. Hard to run a debugger in a docker container.","Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",4th,3rd,2nd,Most,Least,"Make it easier to mock, easier to integration test, easier to unit-test Airflow components directly",Never,Sometimes,Often,Often,Never,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Ability to jump into a specific task/operator with a user-provided state",,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",2,"Some providers disallow remote debugging / shell access, the integrated terminal / file browser could be interested","Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)","Senior team member, Technical supervisor (e.g software architect), Lone developer (e.g. independent consultant)","A project I've wanted to work on was a repository of mocks, docker-compose setups, and sample pytests to aid in integration testing with docker. Would be cool. Would love to have those in the Astronomer Registry",
9/4/2024 22:30:08,"Logs are fragmented across different systems/components, Logs are not verbose enough, Logs are too verbose, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,Stack traces do not provide enough context about the DAG execution state,,2,,"More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue, Integration with visualization tools to trace execution flow",Error messages do not provide clear guidance on resolving issues,,3,G,E,D,C,J,"Source code editor (e.g., VSCode, Sublime Text)",1,2,"Monitoring tools (e.g., Prometheus, Grafana), Local Setup with VSCode","Allow ""Desktop IDE"" Debugging with ease in VSCode","Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",Least,3rd,2nd,Most,4th,"Be ablt to ""high level"" step through the DAG w/o complex debugging setup.",Often,Often,Sometimes,Often,Rarely,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests.",,"Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",Mock Cloud Environment (e.g. Service Credentials/Principals) which are not available locally,Self-Managed Airflow on Kubernetes (using official Helm Chart),1,"Describe it, for me it is not known that this would be possible at-all","Administrator (supported Airflow installations at a platform level), Airflow Committer/PMC Member","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Technical supervisor (e.g software architect),,
9/4/2024 23:36:53,Logs are non-existent or missing in some cases,,,,4,,"More detailed context about the state of the DAG and task at the time of failure, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages are inconsistent across different components",,2,B,C,D,E,J,"Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,1,,A PyCharm plugin specifically for airflow testing and debugging support,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",4th,3rd,2nd,Least,Most,,Rarely,Rarely,Always,Always,Always,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,"Mock dataset events, Store/load the state of a DAG",,Self-Managed Airflow on Docker Swarm,2,,Administrator (supported Airflow installations at a platform level),"DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)","Senior team member, Technical supervisor (e.g software architect)",,
9/5/2024 3:19:44,"Logs are fragmented across different systems/components, Logs are not verbose enough, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,Stack traces do not provide enough context about the DAG execution state,,3,,"Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages lack context or details about the failure",,2,H,E,B,D,A,"Text editor (e.g., Vim, Notepad++), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,4,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana)","Linting, formatting, etc, or LSP source","Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",Most,2nd,3rd,4th,Least,,Often,Sometimes,Often,Sometimes,Rarely,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,"Mock file system queries/reads/writes, Mock network requests/responses, Ability to jump into a specific task/operator with a user-provided state",,"Self-Managed Airflow on Kubernetes (using official Helm Chart), Bare metal or VM-based install",2,Common loga for components,"Advanced (made and debugged several DAGs over the last few years), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow monitoring & availability (e.g. SRE, DevOps)",Senior team member,,
9/5/2024 9:44:42,"Logs are fragmented across different systems/components, Logs are difficult to search and filter",,Stack traces are too complex and hard to follow,,3,,"Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Inclusion of specific suggestions or hints for resolving the issue, Integration with visualization tools to trace execution flow","Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure",,3,A,B,C,D,E,,2,1,"Log management systems (e.g., ELK Stack, Splunk), Debuggers (e.g., pdb, debugpy, PyCharm)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",2nd,Least,Most,4th,3rd,,,,,,,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",3,,"Advanced (made and debugged several DAGs over the last few years), Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level), Airflow Committer/PMC Member","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Senior team member,,
9/5/2024 11:33:27,Logs are fragmented across different systems/components,This is specifically because we are in AWS MWAA which distributes logs to AWS Cloudwatch. So probably not an Airflow specific problem,,,4,,Inclusion of specific suggestions or hints for resolving the issue,,,4,I,H,D,C,J,"Text editor (e.g., Vim, Notepad++), Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",4,5,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",2nd,Most,Least,4th,3rd,,Always,Always,Always,Often,Sometimes,"An integrated terminal in the UI, A file explorer, Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,"Mock dataset events, Ability to jump into a specific task/operator with a user-provided state",,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",2,In our case we have no CLI access in MWAA which is not optimal,"Advanced (made and debugged several DAGs over the last few years), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Senior team member,,
9/5/2024 11:43:10,"Logs are fragmented across different systems/components, Logs are too verbose, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,,,3,"IMO nothing wrong with stacktraces themselves, 99% of the time they point me to the location of faulty code. One specific type however is troublesome -- which are errors resulting from dependency conflicts after upgrades. E.g. recently I upgraded somebody to Airflow 2.9 (I believe it was from 2.7), and something in the KubernetesExecutor code was raising an unrelated exception due to a list being None. We had to upgrade the cncf-kubernetes provider accordingly, but that was unclear from the stacktrace.",Integration with visualization tools to trace execution flow,,,3,J,H,F,I,E,"Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,4,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana), Tracing tools (e.g., Jaeger, Zipkin, OpenTelemetry), Debuggers (e.g., pdb, debugpy, PyCharm)",A PyCharm plugin to run a DAG integrity test/visualize the DAG while you're coding would be nice,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",4th,4th,3rd,Most,2nd,Anything to speed up the feedback loop,Often,Often,Often,Often,Often,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,,,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",1,"Anything to speed up the feedback loop. Going through a deployment cycle for a code change is very time-consuming. Examples: more development options via the UI such as running a single task instead of having to run a complete DAG, per-DAG ability to specify log level, and opening a terminal session similar to GCP Cloud Shell for debugging via the Airflow UI.","Advanced (made and debugged several DAGs over the last few years), Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level), Airflow Committer/PMC Member","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Technical supervisor (e.g software architect),,
9/5/2024 13:21:03,"Logs are fragmented across different systems/components, Logs are not verbose enough, Logs are non-existent or missing in some cases, Logs are difficult to search and filter","1) has been greatly improved by log-forwarding from the triggerer and executor in recent releases
5) a central level keyword search with a couple filters would be awesome",,"No issue with the stack traces, they usually point me to the right places in the source code",5,,"More detailed context about the state of the DAG and task at the time of failure, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues",,3,B,G,D,J,A,"Source code editor (e.g., VSCode, Sublime Text)",4,1,,,"Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",Most,Least,3rd,2nd,4th,Figuring out connection parameters. Not directly an Airflow issue but what I often spend a significant amount of time on.,Sometimes,Never,Never,Sometimes,Never,"An integrated terminal in the UI, A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Ability to jump into a specific task/operator with a user-provided state",,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",3,,Advanced (made and debugged several DAGs over the last few years),"DAG development (e.g. Data Engineer, Software Developer)",Junior team member,,
9/5/2024 18:35:33,Logs are difficult to search and filter,Sometimes when there are too many logs it becomes difficult to filter them in the Airflow UI.,Stack traces are too complex and hard to follow,It would be great to have more control over the length of stack traces (may be a configurable property to adjust stack trace verbosity?).,4,,"More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Enhanced visibility of nested errors and their causes",Error messages are inconsistent across different components,"It would be nice to have consistent Airflow-specific errors codes (e.g. AIRERR-011) across all Airflow components and for DAGs as well. This will be very useful when users are trying to explain their errors to their teammates or to the Airflow community, as they can then directly share the Airflow error code (with additional info if need be).",3,F,,,,,"Text editor (e.g., Vim, Notepad++), Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse), Jupyter Notebooks",4,2,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana), Debuggers (e.g., pdb, debugpy, PyCharm)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",Most,2nd,4th,3rd,Least,,Always,Always,Often,Sometimes,Sometimes,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file.",,"Mock network requests/responses, Store/load the state of a DAG",,"Self-Managed Airflow on Kubernetes (using official Helm Chart), Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",3,"[Kubernetes-specific feedback] A section in the Cluster Activity page showing pod-wise diagnostics for Airflow components would be very useful, so administrators don't have to check pods' status via kubectl commands. The diagnostics can show information like pod readiness, uptime, and other health-related information. And can also include any security-specific warnings for any sort of deployment misconfiguration.","Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)","Technical supervisor (e.g software architect), Lone developer (e.g. independent consultant)",,Lovely survey! :D
9/5/2024 19:00:31,"Logs are fragmented across different systems/components, Logs are non-existent or missing in some cases, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,,Stacktraces are fine as long as tasks are performing activities within Airflow layer.,4,,"Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues",We are using sftpOperator and the operator gives connectivity error that is not explanatory.,2,J,F,,,,"Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",1,5,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana)",Online IDE / Developer mode to add debuggers / breakpoints on the fly,"Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",3rd,2nd,Most,Most,Most,,,,,Often,Always,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,"Mock network requests/responses, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",1,,"Advanced (made and debugged several DAGs over the last few years), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Technical supervisor (e.g software architect),,
9/5/2024 22:31:07,,,,,,,,,,,,,,,,"Source code editor (e.g., VSCode, Sublime Text)",3,1,,,"Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",2nd,2nd,3rd,Most,2nd,,Rarely,Never,Rarely,Never,Rarely,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file.",,,,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",,,Beginner (made a handful of DAGs recently),"DAG development (e.g. Data Engineer, Software Developer), Airflow monitoring & availability (e.g. SRE, DevOps), I have created DAGs for a side project where I'm monitoring and developing at the same time",Lone developer (e.g. independent consultant),,There are a lot more aspects which I haven't touched yet and unfortunately couldn't contribute much however with time will be able to learn these too
9/6/2024 1:26:14,"Logs are fragmented across different systems/components, Logs are not verbose enough",Some logs do not provide clear action items. https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally should not be required; these issues should be actionable or should be fixed.,,"""Celery command failed on host"" BUT WHY?!?!?!?!?!

It was especially frustrating that this exception is caused by dag processor timeouts.",4,,Inclusion of specific suggestions or hints for resolving the issue,Error messages do not provide clear guidance on resolving issues,,2,B,G,H,,,"Text editor (e.g., Vim, Notepad++), Source code editor (e.g., VSCode, Sublime Text)",1,5,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana)",Something to accurately monitor memory usage on a task-by-task basis,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",Most,4th,3rd,2nd,Least,Easier ways to test/simulate DAG runs or individual task instances,,,,,,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests.",,,,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",1,Breakpoints when executing task instances,"Advanced (made and debugged several DAGs over the last few years), Administrator (supported Airflow installations at a platform level), Airflow Committer/PMC Member","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps), Astronomer Support","Senior team member, Non-technical supervisor (e.g. project or product manager)",,
9/6/2024 5:42:39,"Logs are fragmented across different systems/components, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,"Stack traces are too complex and hard to follow, Stack traces do not provide enough context about the DAG execution state",,3,"1. Highlighting any hyperlinks (eg: links to spark jobs)
2. Colour coding for error logs","Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages lack context or details about the failure",,2,A,B,E,G,I,"Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse), Jupyter Notebooks",2,1,,,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",Least,Most,3rd,4th,4th,Official airflow plugin for standard editors and IDEs to support autocomplete and view documentation ,Sometimes,Always,Often,Sometimes,Rarely,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,,,Self-Managed Airflow on Kubernetes (using official Helm Chart),2,,Advanced (made and debugged several DAGs over the last few years),"DAG development (e.g. Data Engineer, Software Developer)",Senior team member,,
9/6/2024 19:31:55,"Logs are non-existent or missing in some cases, Logs are difficult to search and filter",,Stack traces do not provide enough context about the DAG execution state,,4,,"More detailed context about the state of the DAG and task at the time of failure, Enhanced visibility of nested errors and their causes",Error messages are vague or non-specific,,3,B,A,E,G,D,"Source code editor (e.g., VSCode, Sublime Text)",4,4,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint)",4th,Least,Most,2nd,3rd,,Always,Always,Rarely,Rarely,Sometimes,"A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file.",,"Mock file system queries/reads/writes, Mock network requests/responses",,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.), Bare metal or VM-based install",3,,Advanced (made and debugged several DAGs over the last few years),Astronomer CRE,Junior team member,,
9/8/2024 13:27:47,"Logs are fragmented across different systems/components, Logs are too verbose, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,Stack traces do not provide enough context about the DAG execution state,,3,,"Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure","Error messages lack context or details about the failure, Error messages are inconsistent across different components",,2,B,A,D,E,H,"Source code editor (e.g., VSCode, Sublime Text)",2,4,"Monitoring tools (e.g., Prometheus, Grafana), Debuggers (e.g., pdb, debugpy, PyCharm)",Better tooling around attaching debuggers to k8s pods in a local dev environment,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",Least,2nd,Most,3rd,4th,,Sometimes,Often,Often,Often,Often,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,"Mock file system queries/reads/writes, Mock network requests/responses, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,Self-Managed Airflow on Kubernetes (using official Helm Chart),1,Devcontainers?,"Advanced (made and debugged several DAGs over the last few years), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)","Senior team member, Technical supervisor (e.g software architect)",,
9/9/2024 10:42:43,"Logs are fragmented across different systems/components, Logs are non-existent or missing in some cases, Logs are difficult to search and filter","Scheduler errors are not easy to trace, for example, 
Dags parse failure due to DB
Invalid JSON object serialization
Missing Dags - could be a timeout",Stack traces are incomplete or missing critical information,"Connecting the dots between the scheduler & webserver is complex, as not trace information visually available for scheduler.",4,"One-liner explanation of error, Separate error pages with filters & more details would be better.
Visual presentation if possible in Webserver for cross-components","Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Enhanced visibility of nested errors and their causes",Error messages lack context or details about the failure,,3,H,D,A,F,C,"Source code editor (e.g., VSCode, Sublime Text)",2,1,,,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint)",3rd,2nd,Most,4th,Least,,Sometimes,Often,Always,Sometimes,Often,"An integrated terminal in the UI, A file explorer, Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",File explorer of logs file & dags with editing capabilities will make lot easier to fix small bugs,"Mock file system queries/reads/writes, Ability to jump into a specific task/operator with a user-provided state",,"Self-Managed Airflow on Kubernetes (using official Helm Chart), Bare metal or VM-based install",2,,"Advanced (made and debugged several DAGs over the last few years), Administrator (supported Airflow installations at a platform level)","Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)","Technical supervisor (e.g software architect), Lone developer (e.g. independent consultant)",,
9/9/2024 16:53:50,"Logs are fragmented across different systems/components, Logs are not verbose enough, Logs are non-existent or missing in some cases, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,Stack traces are incomplete or missing critical information,Stack trace does not show the full path of the source file. There may be other files with the same name amongst the installed python packages.,4,,"More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure, Error messages are inconsistent across different components",,3,H,B,G,E,A,"Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse), Cloud-based development environments (e.g., AWS Cloud9, GitHub Codespaces)",3,5,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana)",,,4th,Most,3rd,2nd,Least,,Sometimes,Always,Always,Always,Rarely,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,,,"Self-Managed Airflow on Kubernetes (using official Helm Chart), Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",3,,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level), Airflow Committer/PMC Member","Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)","Technical supervisor (e.g software architect), Lone developer (e.g. independent consultant)",,
9/10/2024 0:45:35,"Logs are fragmented across different systems/components, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,Stack traces do not provide enough context about the DAG execution state,,3,,"More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure, Error messages are inconsistent across different components",,1,G,E,D,H,B,"Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",1,1,"Tracing tools (e.g., Jaeger, Zipkin, OpenTelemetry)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",3rd,4th,Most,2nd,Least,,Often,Often,Often,Rarely,Rarely,An integrated terminal in the UI,,"Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",2,,Advanced (made and debugged several DAGs over the last few years),"DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator)",Senior team member,,
9/11/2024 14:14:33,Logs are too verbose,,Stack traces are incomplete or missing critical information,,2,,"Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces",Error messages lack context or details about the failure,,2,A,I,B,,J,"Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse), Jupyter Notebooks",1,4,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana), Debuggers (e.g., pdb, debugpy, PyCharm)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint)",Most,Most,3rd,Most,Least,,Sometimes,Often,Sometimes,Often,Rarely,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file.",code editor in web ui,"Mock file system queries/reads/writes, Mock network requests/responses, Store/load the state of a DAG",,Self-Managed Airflow in docker,3,,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Senior team member,code editor in web ui))),ty for AF - this is a reason of my job)))
9/13/2024 4:39:03,,Logs are not visible while task execution. Visible only after task completion. It will be good if we see running logs. ,,,4,,,,,3,I,J,C,A,D,"Source code editor (e.g., VSCode, Sublime Text), Cloud-based development environments (e.g., AWS Cloud9, GitHub Codespaces)",3,2,"Monitoring tools (e.g., Prometheus, Grafana)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",3rd,2nd,Most,4th,Least,,,,,,,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file.",,Ability to jump into a specific task/operator with a user-provided state,,Self-Managed Airflow on Kubernetes (using official Helm Chart),2,Providing editor from airglow ui and reflect changes and commits to respective repo,"Beginner (made a handful of DAGs recently), Advanced (made and debugged several DAGs over the last few years)","DAG development (e.g. Data Engineer, Software Developer)","Junior team member, Senior team member","1. It will be good if we have direct edit to code from Ui and test
2.increase more number of trigger rules
3. Edit to xcoms from ui
4.provideing stop Or pause and resume option  for tasks and mapped tasks (currently only failed, success and clear task available) 
5. Scale up mapped tasks dynamically even after task starts. 
6.running logs for tasks 
",
9/12/2024 18:13:37,"Logs are fragmented across different systems/components, Logs are not verbose enough, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,"Stack traces are incomplete or missing critical information, Stack traces do not provide enough context about the DAG execution state",,3,,"More detailed context about the state of the DAG and task at the time of failure, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages lack context or details about the failure",,3,,,,,,"Source code editor (e.g., VSCode, Sublime Text)",2,5,,,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",Most,4th,3rd,2nd,Least,,Always,Always,Sometimes,Sometimes,Sometimes,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,Self-Managed Airflow on Kubernetes (using official Helm Chart),3,,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Senior team member,,
9/12/2024 18:13:41,"Logs are non-existent or missing in some cases, Logs are difficult to search and filter",,Stack traces are incomplete or missing critical information,,3,,"More detailed context about the state of the DAG and task at the time of failure, Inclusion of specific suggestions or hints for resolving the issue","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure",,3,A,B,E,,,"Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",3,2,,,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",Most,3rd,2nd,4th,Least,,,,,,,,,,,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",2,,Advanced (made and debugged several DAGs over the last few years),"DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)","Senior team member, Technical supervisor (e.g software architect)",,
9/13/2024 23:09:12,"Logs are fragmented across different systems/components, Logs are non-existent or missing in some cases",,,,4,,"Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages do not provide clear guidance on resolving issues, Error messages are inconsistent across different components",,3,,,,,,"Source code editor (e.g., VSCode, Sublime Text)",3,4,"Monitoring tools (e.g., Prometheus, Grafana), Debuggers (e.g., pdb, debugpy, PyCharm)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint)",Most,,,,,,Always,Always,,Always,Always,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",,"Mock file system queries/reads/writes, Mock network requests/responses, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,Self-Managed Airflow on Kubernetes (using official Helm Chart),1,,"Advanced (made and debugged several DAGs over the last few years), Airflow Committer/PMC Member","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Technical supervisor (e.g software architect),,
9/14/2024 4:20:22,"Logs are fragmented across different systems/components, Logs are not verbose enough, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",Problems to integrate with kubernetes namespace resource quotas,"Stack traces are too complex and hard to follow, Stack traces do not provide enough context about the DAG execution state",,2,,"Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure, Error messages are inconsistent across different components",,2,F,G,I,,,"Source code editor (e.g., VSCode, Sublime Text)",3,4,"Log management systems (e.g., ELK Stack, Splunk), Debuggers (e.g., pdb, debugpy, PyCharm)",Better tests using vscode ,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",3rd,3rd,2nd,Most,Most,Use Yaml and a form for simple dags ,Always,Always,Always,Often,Always,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,Self-Managed Airflow on Kubernetes (using official Helm Chart),1,Easy use with vscode and a connection ssh,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Senior team member,,
9/14/2024 14:04:39,"Logs are too verbose, Logs are non-existent or missing in some cases, Logs are difficult to search and filter",,"Stack traces are too complex and hard to follow, Stack traces do not provide enough context about the DAG execution state",,2,,"Simplified and more readable stack traces, Integration with visualization tools to trace execution flow",Error messages do not provide clear guidance on resolving issues,,2,A,C,G,E,F,"Source code editor (e.g., VSCode, Sublime Text)",1,5,"Monitoring tools (e.g., Prometheus, Grafana)",,"Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",4th,Least,2nd,Most,3rd,,,,,,,,,,,,,,Administrator (supported Airflow installations at a platform level),"DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Senior team member,,
9/17/2024 17:54:23,"Logs are fragmented across different systems/components, Logs are not verbose enough, Logs are non-existent or missing in some cases",,Stack traces do not provide enough context about the DAG execution state,,4,"When an error occurs, it should also include the parsed version of the DAG. This can help us to understand what was the DAG code during the error. When DAG gets replaced, its hard for us to look at traceback as they don't match with the code(if its updated)","More detailed context about the state of the DAG and task at the time of failure, Integration with visualization tools to trace execution flow",Error messages lack context or details about the failure,,3,E,C,G,F,A,"Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,5,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana), Debuggers (e.g., pdb, debugpy, PyCharm)",,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",Most,Least,2nd,4th,3rd,,Always,Always,Always,Always,Always,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,Ability to jump into a specific task/operator with a user-provided state,,"Self-Managed Airflow on Kubernetes (using official Helm Chart), Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",3,,"Advanced (made and debugged several DAGs over the last few years), Administrator (supported Airflow installations at a platform level)","Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)",Junior team member,,
9/17/2024 18:01:41,"Logs are fragmented across different systems/components, Logs are non-existent or missing in some cases, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)","The names of task instances are not consistently formatted across log messages from different components and there is no cuid for a task instance one can easily search. Also, its difficult sometimes to separate task instance logs from different trys of the same instance.",Stack traces do not provide enough context about the DAG execution state,,2,"Elaborating on DAG Execution state, we only get the log line that failed, nothing about what all was being checked at the time. This is especially bad in the scheduler. It's also quite tough to understand what parts are ""Airflow"" and what parts are user code in the stack trace unless you are very familiar with Airflow.

I do not think ""simpler"" should be the goal for stack traces though. More context, more clarity and requiring less esoteric knowledge should be.","More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure",Error messages presume a lot of knowledge of how Airflow works,2,A,E,B,G,J,"Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,5,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana), Debuggers (e.g., pdb, debugpy, PyCharm)","When I'm trying to test a task that's part of a DAG, I wish it would know that I'm not using it as a task _right now_ and behave like just the method I've written, without the Airflow wrapper around it. I know I can do .function or .method or something to get that back out but it feels bad.","Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",2nd,Least,Most,3rd,4th,"If tasks had a better relationship with external resources such that I could define the external resource as an input to the function, rather than retrieving the data from the external resource within the function, then it would be much easier to test. As it is, I often have to make an inner function within the task and test that, but the task as a whole is very hard to test.",Always,Always,Often,Often,Often,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Ability to jump into a specific task/operator with a user-provided state",I don't know why but I rarely reach for DAG.test instead of just launching an Airflow instance and trying it.,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",2,"Make XCOMs work better as integrations with external resources. What if my XCOM represented a Snowflake table or s3 location, and I could click it and follow a link to download the actual data which I could then pipe into the task locally without having to write a bunch of my own mocking","Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)","Senior team member, Technical supervisor (e.g software architect), Non-technical supervisor (e.g. project or product manager)",,
9/19/2024 20:37:53,"Logs are non-existent or missing in some cases, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",some tasks when failed or skipped just have with no context- *** Could not read served logs: Invalid URL,"Stack traces are too complex and hard to follow, Stack traces are incomplete or missing critical information, Stack traces do not provide enough context about the DAG execution state",,3,"1.Provide dependency tracking in the stack trace, showing upstream and downstream tasks in the DAG and their states.
2. Automatically dump relevant variables and environment states at the time of failure. This includes the values of task parameters, XComs, environment variables, and Airflow-specific configurations used during the task execution.
3. Adding Time Information to Stack Traces - 
Provide a breakdown of the time spent on different operations within a task, especially when using operators that involve multiple steps (e.g., fetching data, processing data, loading data). This can highlight where the failure occurred relative to the overall task time.
- If a certain step or function takes an unusually long time before failing, the traceback could include a warning indicating this. For example, a long-running database query might be flagged as a potential cause of the failure.","Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes, Integration with visualization tools to trace execution flow","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues, Error messages lack context or details about the failure, Error messages are inconsistent across different components",,2,D,E,G,I,A,"Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",1,1,,"1. Integration with remote debuggers like PyCharm or Visual Studio Code (VS Code), allowing breakpoints and step-through debugging on a live Airflow environment.
2. An in-browser task-level debugging console within the Airflow UI where you can inspect task state, inputs, outputs, and intermediate results.","Formatters (e.g. Black, Ruff-format, autopep8)",Least,Most,2nd,3rd,4th,"1. Simulate DAG Inputs: Add built-in support for simulating inputs like data_interval_start, execution_date, and other task_instance variables, allowing developers to test DAG behavior without waiting for real executions
2. DAG Templates: Provide pre-built templates for common patterns (e.g., ETL pipelines) to streamline DAG authoring. This reduces repetitive setup and ensures best practices are followed.
3. Visual DAG Authoring: A visual editor within Airflow could allow developers to graphically drag-and-drop tasks and define dependencies, which would reduce syntax errors and improve understanding.",Always,Sometimes,Sometimes,Often,Never,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file., Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications., Integration with task management platforms (e.g. Trello, Jira) to streamline the opening of feature/bug tickets.",,"Mock file system queries/reads/writes, Mock network requests/responses, Mock dataset events, Store/load the state of a DAG, Ability to jump into a specific task/operator with a user-provided state",,Bare metal or VM-based install,1,,Advanced (made and debugged several DAGs over the last few years),"DAG development (e.g. Data Engineer, Software Developer)",,,
9/20/2024 3:00:27,Logs are difficult to search and filter,,Stack traces do not provide enough context about the DAG execution state,,2,,"Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue",Error messages do not provide clear guidance on resolving issues,,2,D,E,F,G,,"Source code editor (e.g., VSCode, Sublime Text), Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",2,2,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana)",,"Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",4th,2nd,Most,3rd,3rd,,,,,,,"An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), Ability to make temporary/permanent changes to DAG code, potentially exporting as a new file.",,Mock network requests/responses,,"Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",2,,Advanced (made and debugged several DAGs over the last few years),Airflow administration (e.g. Administrator),Senior team member,,
9/20/2024 13:53:42,"Logs are not verbose enough, Logs are difficult to search and filter","real error can be hidden by too many layers of error propagation. For example, running a shell script that calls a python script that catches an error can hide exactly where in code the error happens",Stack traces are incomplete or missing critical information,,3,,"Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue","Error messages are vague or non-specific, Error messages do not provide clear guidance on resolving issues",,3,C,C,C,C,C,"Source code editor (e.g., VSCode, Sublime Text)",1,1,,,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",Most,4th,Most,2nd,3rd,,Never,Never,Sometimes,Sometimes,Sometimes,A file explorer,,Mock file system queries/reads/writes,,,1,,Advanced (made and debugged several DAGs over the last few years),"DAG development (e.g. Data Engineer, Software Developer)",Senior team member,,
9/23/2024 16:34:07,"Logs are non-existent or missing in some cases, Logs are difficult to search and filter, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)",,Stack traces are incomplete or missing critical information,"In particular, stack traces from DAGs failing to parse are often missing the complete trace when they appear in the red bar at the top of the main page of the UI.",3,,"Simplified and more readable stack traces, Inclusion of specific suggestions or hints for resolving the issue, Enhanced visibility of nested errors and their causes",,,3,D,B,A,,,"Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse)",1,1,"Profiling tools (e.g. cProfile, Austin)",Better support for running Airflow locally,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8), Auto-completion and AI tools (e.g. Copilot, IntelliSense, Cursor)",Least,4th,Most,3rd,2nd,Better support for fully local development workflows,,,,,,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.",Direct integration with GitHub,,,Self-Managed Airflow on Kubernetes (using official Helm Chart),1,"Faster DAG parsing, parse when change detected","Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator)",Senior team member,,
9/23/2024 16:58:27,"Logs are fragmented across different systems/components, Logs are not aligned to technical layers/responsibilities (infrastructure, application, business logic)","Many developers do not understand Airflow architecture and are unable to even locate stacktraces that help identify the problem. For example, if task fails because the DAG fails to parse on a worker, but it parses successfully on the scheduler, there are no logs shown at all.",,,,,"Better correlation between different logs and stack traces, Inclusion of specific suggestions or hints for resolving the issue",,,3,,,,,,"Text editor (e.g., Vim, Notepad++)",2,4,"Log management systems (e.g., ELK Stack, Splunk), Monitoring tools (e.g., Prometheus, Grafana), Profiling tools (e.g. cProfile, Austin), Debuggers (e.g., pdb, debugpy, PyCharm)","I would love to see `airflow standalone` work with MySQL or Postgres with the same ease as SQLite. Not having concurrency is pretty limiting and I find that SQLite locks up a lot even with a single-threaded executor, if you have a lot of tasks. The beauty of standalone is that the user doesn't even need to know about SQLite. It would be awesome if Airflow could transparently stand up MySQL or PG in a similar fashion.","Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",3rd,2nd,Most,4th,Least,,Always,Always,Always,Always,Always,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.), A file explorer, Ability to package the code and necessary debugging context to allow reproducing the issue on another airflow instance, to facilitate bug reports and help requests., Integration with SCM platforms (e.g. GitHub, Bitbucket, GitLab) to streamline code modifications.","The DAG deployment process is painful. Most setups involve uploading to cloud storage, followed by Airflow pods or instances syncing the changes. It is very difficult for developers to understand when their changes have actually been fully synced. They need to understand Airflow architecture first to answer that question.

1. Are my changes task execution only? Need worker pods sync my changes. Usually doesn't take too long.
2. Do my changes modify DAG execution? Need scheduler pods to sync my changes, _and_ need the scheduler loop to make it back to my DAG. Can potentially take several minutes or more.

The net result is that the iteration cycle for remote Airflow is:

1. Upload
2. Wait a few minutes, potentially longer depending on scheduler resources, number of DAGs, etc
3. Try, and if your changes clearly didn't make it then wait longer.",Ability to jump into a specific task/operator with a user-provided state,"Task concurrency would be amazing for larger DAGs, but requires not SQLite","Self-Managed Airflow on Kubernetes (using official Helm Chart), Managed Airflow by a cloud provider (Astronomer, AWS, Azure, GCP etc.)",1,,"Power user (made and debugged DAGs for several years using pdb, IDE or remote debuggers, etc.), Administrator (supported Airflow installations at a platform level)","DAG development (e.g. Data Engineer, Software Developer), Airflow administration (e.g. Administrator), Airflow monitoring & availability (e.g. SRE, DevOps)","Senior team member, Technical supervisor (e.g software architect)",,
9/23/2024 17:30:34,Logs are non-existent or missing in some cases,,Stack traces are too complex and hard to follow,,2,,"Simplified and more readable stack traces, More detailed context about the state of the DAG and task at the time of failure, Enhanced visibility of nested errors and their causes",Error messages do not provide clear guidance on resolving issues,,2,B,A,D,E,G,"Integrated Development Environment (IDE) (e.g., PyCharm, Eclipse), Jupyter Notebooks, BigQuery",2,1,,,"Linters (e.g. Flake8, Ruff-lint, Mypy, Pylint), Formatters (e.g. Black, Ruff-format, autopep8)",Least,3rd,Most,2nd,4th,The ability to locally run DAGs could lead to much quicker iteration,Always,Always,Sometimes,Sometimes,Rarely,"An integrated terminal in the UI, An integrated debugger (for stepping, pause-on-error, workspace inspection and modification, etc.)",,"Mock file system queries/reads/writes, Mock dataset events",,Self-Managed Airflow on Kubernetes (using official Helm Chart),2,,Advanced (made and debugged several DAGs over the last few years),"DAG development (e.g. Data Engineer, Software Developer)",Senior team member,,
